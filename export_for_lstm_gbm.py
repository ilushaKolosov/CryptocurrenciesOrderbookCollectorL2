import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
from database import DATABASE_URL
import json
from datetime import datetime, timedelta
import argparse
import os
from config import TOP_CRYPTO_SYMBOLS


class OptimizedDatasetExporter:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä –≥–æ—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è LSTM+LightGBM (~50-60 —Ñ–∏—á–µ–π) —Å multi-task —Ç–∞—Ä–≥–µ—Ç–∞–º–∏"""
    
    def __init__(self):
        self.engine = create_engine(DATABASE_URL)
        
    def calculate_market_pressure(self, bids, asks, depth=100):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ market pressure"""
        if not bids or not asks:
            return {}
        
        buy_pressure = 0
        sell_pressure = 0
        mid_price = (bids[0]['price'] + asks[0]['price']) / 2
        
        for i, bid in enumerate(bids[:depth]):
            weight = 1.0 / (i + 1)
            distance = (mid_price - bid['price']) / mid_price
            buy_pressure += bid['volume'] * weight * (1 - distance)
        
        for i, ask in enumerate(asks[:depth]):
            weight = 1.0 / (i + 1)
            distance = (ask['price'] - mid_price) / mid_price
            sell_pressure += ask['volume'] * weight * (1 - distance)
        
        total_pressure = buy_pressure + sell_pressure
        net_pressure = buy_pressure - sell_pressure
        pressure_ratio = buy_pressure / sell_pressure if sell_pressure > 0 else 1.0
        
        return {
            'buy_pressure': buy_pressure,
            'sell_pressure': sell_pressure,
            'net_pressure': net_pressure,
            'pressure_ratio': pressure_ratio,
            'total_pressure': total_pressure
        }
    
    def find_orderbook_wall_level(self, volumes, threshold=0.15):
        """–ù–∞—Ö–æ–¥–∏—Ç –±–ª–∏–∂–∞–π—à–∏–π —É—Ä–æ–≤–µ–Ω—å —Å –∫—Ä—É–ø–Ω–æ–π —Å—Ç–µ–Ω–æ–π (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ mid_price)"""
        total = sum(volumes)
        for i, v in enumerate(volumes):
            if v > threshold * total:
                return i + 1  # —É—Ä–æ–≤–µ–Ω—å (1-–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è)
        return np.nan  # –µ—Å–ª–∏ —Å—Ç–µ–Ω—ã –Ω–µ—Ç

    def extract_optimized_features(self, bids, asks, depth=100):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤–º–µ—Å—Ç–æ 400 —Ñ–∏—á–µ–π - ~50)"""
        features = {}
        
        if not bids or not asks:
            return features
        
        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–Ω—ã
        best_bid = bids[0]['price']
        best_ask = asks[0]['price']
        mid_price = (best_bid + best_ask) / 2
        spread = best_ask - best_bid
        spread_percent = (spread / mid_price) * 100
        
        features['mid_price'] = mid_price
        features['spread'] = spread
        features['spread_percent'] = spread_percent
        
        # Market Pressure
        pressure = self.calculate_market_pressure(bids, asks, depth)
        features.update(pressure)
        
        # üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –í–º–µ—Å—Ç–æ 100 —É—Ä–æ–≤–Ω–µ–π - –∫–ª—é—á–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏
        # –¢–æ–ø-10 —É—Ä–æ–≤–Ω–µ–π (—Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ)
        for i in range(10):
            if i < len(bids):
                features[f'bid_price_norm_{i+1}'] = (bids[i]['price'] - mid_price) / mid_price
                features[f'bid_volume_{i+1}'] = bids[i]['volume']
            else:
                features[f'bid_price_norm_{i+1}'] = 0.0
                features[f'bid_volume_{i+1}'] = 0.0
                
            if i < len(asks):
                features[f'ask_price_norm_{i+1}'] = (asks[i]['price'] - mid_price) / mid_price
                features[f'ask_volume_{i+1}'] = asks[i]['volume']
            else:
                features[f'ask_price_norm_{i+1}'] = 0.0
                features[f'ask_volume_{i+1}'] = 0.0
        
        # üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ö–ª—é—á–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏ (25, 50, 75, 100)
        key_levels = [25, 50, 75, 100]
        for level in key_levels:
            if level <= len(bids):
                features[f'bid_price_norm_level_{level}'] = (bids[level-1]['price'] - mid_price) / mid_price
                features[f'bid_volume_level_{level}'] = bids[level-1]['volume']
            else:
                features[f'bid_price_norm_level_{level}'] = 0.0
                features[f'bid_volume_level_{level}'] = 0.0
                
            if level <= len(asks):
                features[f'ask_price_norm_level_{level}'] = (asks[level-1]['price'] - mid_price) / mid_price
                features[f'ask_volume_level_{level}'] = asks[level-1]['volume']
            else:
                features[f'ask_price_norm_level_{level}'] = 0.0
                features[f'ask_volume_level_{level}'] = 0.0
        
        # üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–º–µ—Å—Ç–æ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π
        bid_prices = [b['price'] for b in bids[:depth]]
        bid_volumes = [b['volume'] for b in bids[:depth]]
        ask_prices = [a['price'] for a in asks[:depth]]
        ask_volumes = [a['volume'] for a in asks[:depth]]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è LightGBM
        total_bid_volume = sum(bid_volumes)
        total_ask_volume = sum(ask_volumes)
        volume_imbalance = (total_bid_volume - total_ask_volume) / (total_bid_volume + total_ask_volume)
        
        features['total_bid_volume'] = total_bid_volume
        features['total_ask_volume'] = total_ask_volume
        features['volume_imbalance'] = volume_imbalance
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        features['bid_price_mean'] = np.mean(bid_prices)
        features['ask_price_mean'] = np.mean(ask_prices)
        features['bid_volume_mean'] = np.mean(bid_volumes)
        features['ask_volume_mean'] = np.mean(ask_volumes)
        
        features['bid_price_std'] = np.std(bid_prices)
        features['ask_price_std'] = np.std(ask_prices)
        features['bid_volume_std'] = np.std(bid_volumes)
        features['ask_volume_std'] = np.std(ask_volumes)
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –æ–±—ä–µ–º–æ–≤
        features['bid_volume_concentration'] = np.sum(np.array(bid_volumes[:10])) / total_bid_volume if total_bid_volume > 0 else 0
        features['ask_volume_concentration'] = np.sum(np.array(ask_volumes[:10])) / total_ask_volume if total_ask_volume > 0 else 0
        
        # üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        # –ö–≤–∞–Ω—Ç–∏–ª–∏ —Ü–µ–Ω –∏ –æ–±—ä–µ–º–æ–≤
        features['bid_price_q25'] = np.percentile(bid_prices, 25)
        features['bid_price_q75'] = np.percentile(bid_prices, 75)
        features['ask_price_q25'] = np.percentile(ask_prices, 25)
        features['ask_price_q75'] = np.percentile(ask_prices, 75)
        
        features['bid_volume_q25'] = np.percentile(bid_volumes, 25)
        features['bid_volume_q75'] = np.percentile(bid_volumes, 75)
        features['ask_volume_q25'] = np.percentile(ask_volumes, 25)
        features['ask_volume_q75'] = np.percentile(ask_volumes, 75)
        
        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –æ–±—ä–µ–º–æ–≤ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö
        features['volume_ratio_top10'] = sum(bid_volumes[:10]) / sum(ask_volumes[:10]) if sum(ask_volumes[:10]) > 0 else 1.0
        features['volume_ratio_top25'] = sum(bid_volumes[:25]) / sum(ask_volumes[:25]) if sum(ask_volumes[:25]) > 0 else 1.0
        features['volume_ratio_top50'] = sum(bid_volumes[:50]) / sum(ask_volumes[:50]) if sum(ask_volumes[:50]) > 0 else 1.0
        
        return features
    
    def add_targets(self, df, future_shift=30, wall_threshold=0.15):
        """–î–æ–±–∞–≤–ª—è–µ—Ç multi-task —Ç–∞—Ä–≥–µ—Ç—ã: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (—Ä–æ—Å—Ç/–ø–∞–¥–µ–Ω–∏–µ) –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è (—É—Ä–æ–≤–µ–Ω—å –¥–ª—è –ª–∏–º–∏—Ç–Ω–æ–≥–æ –æ—Ä–¥–µ—Ä–∞)"""
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: —Ä–æ—Å—Ç/–ø–∞–¥–µ–Ω–∏–µ future_mid_price
        df['future_mid_price'] = df['mid_price'].shift(-future_shift)
        df['target_updown'] = (df['future_mid_price'] > df['mid_price']).astype(int)
        # –†–µ–≥—Ä–µ—Å—Å–∏—è: –±–ª–∏–∂–∞–π—à–∏–π —É—Ä–æ–≤–µ–Ω—å –∫—Ä—É–ø–Ω–æ–π bid/ask-—Å—Ç–µ–Ω—ã
        bid_cols = [f'bid_volume_{i+1}' for i in range(10)]
        ask_cols = [f'ask_volume_{i+1}' for i in range(10)]
        df['bid_wall_level'] = df[bid_cols].apply(lambda row: self.find_orderbook_wall_level(row.values, wall_threshold), axis=1)
        df['ask_wall_level'] = df[ask_cols].apply(lambda row: self.find_orderbook_wall_level(row.values, wall_threshold), axis=1)
        return df

    def export_dataset(self, symbol: str, start_time: datetime, end_time: datetime, output_dir: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        query = text("""
            SELECT timestamp, bids, asks
            FROM orderbook_entries 
            WHERE symbol = :symbol 
            AND timestamp >= :start_time 
            AND timestamp <= :end_time
            ORDER BY timestamp ASC
        """)
        
        print(f"üìä –≠–∫—Å–ø–æ—Ä—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è {symbol}...")
        
        data_rows = []
        
        with self.engine.connect() as conn:
            result = conn.execute(query, {
                "symbol": symbol, 
                "start_time": start_time, 
                "end_time": end_time
            })
            
            for row in result:
                bids = json.loads(row.bids)
                asks = json.loads(row.asks)
                
                features = self.extract_optimized_features(bids, asks)
                features['timestamp'] = row.timestamp
                features['symbol'] = symbol
                data_rows.append(features)
        
        if data_rows:
            df = pd.DataFrame(data_rows)
            
            # –î–æ–±–∞–≤–ª—è–µ–º multi-task targets
            df = self.add_targets(df, future_shift=30, wall_threshold=0.15)
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(output_dir, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            dataset_file = f"{output_dir}/{symbol}_optimized_dataset_{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}.csv"
            df.to_csv(dataset_file, index=False)
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è LSTM (—Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            lstm_matrix = df[numeric_cols].values
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Ç—Ä–∏—Ü—É
            matrix_file = f"{output_dir}/{symbol}_optimized_lstm_matrix_{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}.npy"
            np.save(matrix_file, lstm_matrix)
            
            print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω:")
            print(f"  üìÅ –ü–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {dataset_file} ({len(df)} –∑–∞–ø–∏—Å–µ–π, {len(df.columns)} —Ñ–∏—á–µ–π)")
            print(f"  üß† LSTM –º–∞—Ç—Ä–∏—Ü–∞: {matrix_file} (—Ñ–æ—Ä–º–∞: {lstm_matrix.shape})")
            
            return df
        else:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return None
    
    def export_all_symbols(self, symbols: list, hours: int = 24, output_dir: str = "dataset"):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)
        
        print(f"üöÄ –≠–∫—Å–ø–æ—Ä—Ç –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è LSTM+LightGBM")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_time} - {end_time}")
        print(f"üéØ –°–∏–º–≤–æ–ª—ã: {symbols}")
        print(f"üìä –í–º–µ—Å—Ç–æ 439+ —Ñ–∏—á–µ–π - ~50-60 —Ñ–∏—á–µ–π")
        print("=" * 60)
        
        all_datasets = []
        
        for symbol in symbols:
            df = self.export_dataset(symbol, start_time, end_time, output_dir)
            if df is not None:
                all_datasets.append(df)
                print(f"‚úÖ {symbol}: {len(df)} –∑–∞–ø–∏—Å–µ–π, {len(df.columns)} —Ñ–∏—á–µ–π")
            else:
                print(f"‚ùå {symbol}: –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        if all_datasets:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
            combined_df = pd.concat(all_datasets, ignore_index=True)
            combined_file = f"{output_dir}/combined_optimized_dataset_{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}.csv"
            combined_df.to_csv(combined_file, index=False)
            
            print("=" * 60)
            print(f"üéâ –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–ô –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {combined_file}")
            print(f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"   - –ó–∞–ø–∏—Å–µ–π: {len(combined_df)}")
            print(f"   - –§–∏—á–µ–π: {len(combined_df.columns)}")
            print(f"   - –°–∏–º–≤–æ–ª–æ–≤: {len(combined_df['symbol'].unique())}")
            print(f"   - –ü–µ—Ä–∏–æ–¥: {combined_df['timestamp'].min()} - {combined_df['timestamp'].max()}")
        
        return all_datasets


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–≠–∫—Å–ø–æ—Ä—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è LSTM+LightGBM')
    parser.add_argument('--hours', type=int, default=24, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 24)')
    parser.add_argument('--output', type=str, default='dataset', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: dataset)')
    parser.add_argument('--symbols', nargs='+', default=TOP_CRYPTO_SYMBOLS, help='–°–∏–º–≤–æ–ª—ã –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞')
    
    args = parser.parse_args()
    
    exporter = OptimizedDatasetExporter()
    exporter.export_all_symbols(args.symbols, args.hours, args.output)


if __name__ == "__main__":
    main() 